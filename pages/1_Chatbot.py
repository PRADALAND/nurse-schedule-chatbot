# pages/1_Chatbot.py
import streamlit as st
import pandas as pd

from utils.features import (
    compute_longest_work_streak,
    compute_longest_night_streak,
    find_peak_risk_info,
)
from utils.risk import risk_level
from utils.analysis_log import log_analysis
from utils.free_ai import analyze_query_free


st.title("ê·¼ë¬´ ìŠ¤ì¼€ì¤„ ì±—ë´‡")

# ==========================
# ìŠ¤ì¼€ì¤„ ë°ì´í„° í™•ì¸
# ==========================
df = st.session_state.get("schedule_df", None)

if df is None:
    st.warning("ìŠ¤ì¼€ì¤„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë©”ì¸ íŽ˜ì´ì§€ì—ì„œ ìŠ¤ì¼€ì¤„ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

# date ì»¬ëŸ¼ì´ datetimeì´ ì•„ë‹ˆë©´ ë³€í™˜
if not pd.api.types.is_datetime64_any_dtype(df["date"]):
    df["date"] = pd.to_datetime(df["date"])

# ==========================
# ì‚¬ìš©ìž ìž…ë ¥
# ==========================
st.subheader("ìžì—°ì–´ë¡œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”")
query = st.text_input(
    "ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”:",
    placeholder="ì˜ˆ: ì´ë²ˆë‹¬ ë‚´ ì•¼ê°„ ê·¼ë¬´ëž‘ ìœ„í—˜ë„ ìš”ì•½í•´ì¤˜",
)

if st.button("ë¶„ì„ ìš”ì²­"):
    if not query.strip():
        st.warning("ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”.")
        st.stop()

    # ------------------------------
    # 1) AI/ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ì§ˆì˜ í•´ì„
    # ------------------------------
    parsed = analyze_query_free(query, df)
    target_nurse = parsed.get("nurse_name")
    start_s = parsed.get("start_date")
    end_s = parsed.get("end_date")
    qtype = parsed.get("question_type", "summary")

    try:
        start = pd.to_datetime(start_s).date()
        end = pd.to_datetime(end_s).date()
    except Exception:
        start = df["date"].min().date()
        end = df["date"].max().date()

    # ------------------------------
    # 2) ìŠ¤ì¼€ì¤„ í•„í„°ë§
    # ------------------------------
    mask = (df["date"] >= pd.Timestamp(start)) & (df["date"] <= pd.Timestamp(end))
    df_slice = df[mask].copy()

    if target_nurse is not None and "nurse_name" in df_slice.columns:
        df_slice = df_slice[df_slice["nurse_name"] == target_nurse]

    if df_slice.empty:
        response = f"{start}~{end} êµ¬ê°„ì— í•´ë‹¹í•˜ëŠ” ìŠ¤ì¼€ì¤„ì´ ì—†ìŠµë‹ˆë‹¤."
        st.write(response)
        log_analysis(query, response, meta={"parsed": parsed})
        st.stop()

    # ------------------------------
    # 3) ê¸°ë³¸ ìš”ì•½ ê³„ì‚°
    # ------------------------------
    n_work = (df_slice["shift_type"] != "OFF").sum()
    n_night = (df_slice["shift_type"] == "NIGHT").sum()

    # ì—°ì† ê·¼ë¬´, ì—°ì† ì•¼ê°„, í”¼í¬ ìœ„í—˜ë„ ë“±ë„ ìžˆìœ¼ë©´ ê³„ì‚°
    longest_work = compute_longest_work_streak(df_slice)
    longest_night = compute_longest_night_streak(df_slice)
    peak_info = find_peak_risk_info(df_slice)  # ì˜ˆ: (ë‚ ì§œ, ìœ„í—˜ë„ ì ìˆ˜)

    # ------------------------------
    # 4) í•œêµ­ì–´ ìžì—°ì–´ ì‘ë‹µ ìƒì„± (LLM ìœ ë¬´ì™€ ë¬´ê´€í•˜ê²Œ ì—¬ê¸°ì„œëŠ” í¬ë§·íŒ…)
    # ------------------------------
    subject = target_nurse if target_nurse else "ì „ì²´ ê°„í˜¸ì‚¬"

    response_lines = []
    response_lines.append(
        f"ðŸ“… ë¶„ì„ ê¸°ê°„: {start} ~ {end}"
    )
    response_lines.append(
        f"ðŸ‘¤ ëŒ€ìƒ: {subject}"
    )
    response_lines.append(
        f"â€¢ ê·¼ë¬´ì¼ìˆ˜: {int(n_work)}ì¼ (OFF ì œì™¸)"
    )
    response_lines.append(
        f"â€¢ ì•¼ê°„ ê·¼ë¬´: {int(n_night)}íšŒ"
    )
    if longest_work is not None:
        response_lines.append(
            f"â€¢ ìµœìž¥ ì—°ì† ê·¼ë¬´: {longest_work}ì¼"
        )
    if longest_night is not None:
        response_lines.append(
            f"â€¢ ìµœìž¥ ì—°ì† ì•¼ê°„: {longest_night}ì¼"
        )
    if peak_info is not None:
        peak_date, peak_score = peak_info
        level = risk_level(peak_score)
        response_lines.append(
            f"â€¢ ìµœê³  ìœ„í—˜ë„ ë‚ ì§œ: {peak_date} (ì ìˆ˜ {peak_score:.2f}, ë“±ê¸‰ {level})"
        )

    response_lines.append("")
    response_lines.append("ìš”ì•½í•˜ë©´, ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ì „ì²´ ê·¼ë¬´ íŒ¨í„´ê³¼ ì•¼ê°„ íŽ¸ì¤‘, "
                          "ìœ„í—˜ë„ê°€ ê°€ìž¥ ë†’ì•˜ë˜ ì‹œì ì„ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ìŠ¤ì¼€ì¤„ ë¶€ë‹´ì„ íŒŒì•…í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")

    response = "\n".join(response_lines)

    # í™”ë©´ ì¶œë ¥
    st.markdown(response.replace("\n", "  \n"))

    # ------------------------------
    # 5) ë¡œê·¸ ì €ìž¥
    # ------------------------------
    meta = {
        "parsed": parsed,
        "n_rows": int(len(df_slice)),
    }
    log_analysis(query, response, meta=meta)
